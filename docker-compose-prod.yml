version: '3.8'
name: sonar-backend_prod
# NOTE: Currently, we point to the same .prod.env file for every service, 
# which means they will have the same environment variables.

# Alternatively, we can define environment variables for each individual service. 
# For example:
#     environment:
#       POSTGRES_USER: db1
#       POSTGRES_PASSWORD: password123

# Another approach would be to create separate, service-specific .env files 
# (e.g., .postgres.prod.env, .django.prod.env) and adjust the file name 
# in the `env_file` directive accordingly for each service.


# NOTE:
# * Environment variables declared in the .env file cannot then be referenced again separately in the compose file.
# * If you use both the env_file and environment attribute, environment variables set by environment take precedence.

services:

  redis:
    image: redis:7
    container_name: sonar-cache
    restart: unless-stopped
    # ports:
    #  - 6379

  postgres:
    image: postgres:alpine
    container_name: sonar-db
    restart: unless-stopped
    command: -c config_file=/etc/postgresql/postgresql.conf
    env_file:
      - .prod.env
    volumes:
      - ${POSTGRES_CONFIG_FILE}:/etc/postgresql/postgresql.conf
      # NOTE: Shall we have to create another .initdb.sh file for prod?
      - ./conf/initdb/:/docker-entrypoint-initdb.d/
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 10s

  sonar-backend-django:
    image: backend:latest # hint: must be built before, use "build_docker_dev.ps1"
    env_file:
      - .prod.env
    container_name: sonar-backend-django
    restart: unless-stopped
    command: >
       bash -c "python manage.py collectstatic --noinput && gunicorn --workers ${GUNI_WORKERS} --threads ${GUNI_THREADS} --bind 0.0.0.0:9080 covsonar_backend.wsgi:application "
    volumes:
      # TODO-WARNING: find a better way to link files
      - static:/code/covsonar_backend/static
      - ${LOG_PATH}:/tmp/logs/
      - sonar_work_dir:/mnt/c/works/tmp/prod/

      # - ${LOG_PATH}:/tmp/sonar_backend/logs
      # # working directory of import process
      # - ${SONAR_DATA_ENTRY_FOLDER}:/tmp/sonar_backend/import_data
      # - ${SONAR_DATA_PROCESSING_FOLDER}:/tmp/sonar_backend/import_data
      # - ${SONAR_DATA_ARCHIVE}:/tmp/sonar_backend/import_data
      # - /tmp/sonar_backend/import_data:${SONAR_DATA_ENTRY_FOLDER}
      # - /tmp/sonar_backend/processing_data:${SONAR_DATA_PROCESSING_FOLDER}
      # - /tmp/sonar_backend/archive_data:${SONAR_DATA_ARCHIVE}
    depends_on:
      redis:
        condition: service_started
      postgres:
        condition: service_healthy
    # ports:
    #   # to access directly, normally can use localhost:8000 via the nginx proxy
    #   - "9080"

  sonar-apscheduler-django:
    image: backend:latest # hint: must be built before, use "build_docker_dev.ps1"
    env_file:
      - .prod.env
    container_name: sonar-apscheduler-django
    restart: on-failure
    command: >
      bash -c "python manage.py runapscheduler"
    depends_on:
      postgres:
        condition: service_healthy

  celery-workers:
    container_name: celery-workers
    image: backend:latest
    # The workers (concurrency, autoscale) are affected by the SAMPLE_BATCH_SIZE parameter in backend. For example, 
    # if the concurrency is set too high and the SAMPLE_BATCH_SIZE is too high,
    # this will not speed up the process. You need to lower SAMPLE_BATCH_SIZE into smaller chunks to gain the benefits
    # --autoscale max, min  means will have at least min and at most max concurrent worker subprocesses for a given worker instance.
    # command: celery -A covsonar_backend worker --loglevel DEBUG -Ofair  --autoscale=5,0 -E --max-tasks-per-child 15 --time-limit 180
    # --concurrency=N means will have exactly N worker subprocesses for your worker instance (meaning the worker instance can handle N conccurent tasks).
    command: celery -A covsonar_backend worker --loglevel DEBUG -Ofair  --concurrency=${CELERY_CONCURRENCY} -E --max-tasks-per-child=${CELERY_MAX_TASKS} --time-limit 600 -n Bob
    volumes:
      - sonar_work_dir:/mnt/c/works/tmp/prod/ # working directory of import process
    env_file:
      - .prod.env
    depends_on:
      - redis
      - sonar-backend-django

  celery-monitor:
    container_name: celery-monitor
    image: backend_dev:local
    command: celery -A covsonar_backend flower --port=5555 --basic_auth=${BASIC_AUTH} --enable_events=False
    env_file:
      - .prod.env
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - sonar-backend-django
      - celery-workers

  backend-nginx:
    container_name: nginx-prod
    build:
      context: ./nginx
    volumes:
      - static:/var/www/html/static
      # overwrite 
      - ./nginx/prod.conf:/etc/nginx/conf.d/default.conf
    ports:
      - "8000:8000"
    depends_on:
      - "sonar-backend-django"

volumes:
  static:
  sonar_work_dir:
